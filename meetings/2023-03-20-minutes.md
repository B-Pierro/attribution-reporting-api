# Attribution Reporting API

March 20, 2023 @ 8am PT

This doc: [bit.ly/ara-meeting-notes](bit.ly/ara-meeting-notes)

Meet link: [https://meet.google.com/jnn-rhxv-nsy](https://meet.google.com/jnn-rhxv-nsy)

Previous meetings: [https://github.com/WICG/conversion-measurement-api/tree/main/meetings](https://github.com/WICG/conversion-measurement-api/tree/main/meetings)

Meeting issue: [https://github.com/WICG/conversion-measurement-api/issues/80](https://github.com/WICG/conversion-measurement-api/issues/80)



* Use Google meet “Raise hand” for queuing.
* If you can’t edit the doc during the meeting, try refreshing as permissions may have been updated after you loaded the page.
* If you are not admitted to the meeting, try rejoining. Google Meet has some UI that makes it easy to misclick if someone simultaneously requests to join while someone else is typing into the meeting chat.
* Please make sure to join [W3C](https://www.w3.org/) and [WICG](https://www.w3.org/community/wicg/) if you plan on participating


# Agenda



* Chair: Charlie Harrison
* Scribe volunteer: 

Please suggest agenda topics here! (either in a comment or a suggestion on the doc:



* [Charlie Harrison] High level thoughts on reducing delay in aggregatable reports
* [Renan Feldman] Extra report delay for aggregatable reports
    * [https://github.com/WICG/attribution-reporting-api/issues/724](https://github.com/WICG/attribution-reporting-api/issues/724)
* [Akash Nadan / Charlie Harrison] Reporting origin rate limit
    * [https://github.com/WICG/attribution-reporting-api/issues/725](https://github.com/WICG/attribution-reporting-api/issues/725)
* 


# Attendees — please sign yourself in! 

(Please sign in at the start of the meeting)



1. Charlie Harrison (Google Chrome)
2. Renan Feldman (Google Chrome)
3. Brian May (dstillery)
4. 
5. Aloïs Bissuel (Criteo)
6. Matt Lamont (AdTheorent)
7. Sid Sahoo (Google Chrome)
8. Maybelline Boon (Google Chrome)
9. Robert Kubis (Google Chrome)
10. Akash Nadan (Google Chrome)
11. Stacy Andrade (AdTheorent)
12. Nan Lin (Google Chrome)
13. Aleksei Danilov (Criteo)
14. Andrew Pascoe (NextRoll)
15. Risako Hamano (Yahoo Japan)
16. 


# Notes

Reporting Delays



1. Charlie
    1. both event level and aggregatable, report delay. Event level we have prespecified windows (3 windows for clicks). Up to 1 hour for aggregate reports
    2. Delays seem to hurt utility. Looking at mitigations
    3. More likely to be able to mitigate aggregate delays
    4. Looking for feedback on the source_registration_time being available in the report. It can encode 5 bits of information
    5. Thinking of offering a mode of the API that takes source_registration_time taken out but reduces the aggregate delay
    6. Charlie to write up a github issue for this
    7. Is source_registration_time an important aspect for use cases? Specifically it’s presence outside of the aggregation key because it can be encoded in the keys
    8. Related issue: protecting the number of encrypted reports (in the aggregate explainer)
2. Brian
    9. Have you considered using a neutral server for the reports rather than changing timing?
3. Charlie
    10. We have thought about it. An IP proxy could help mitigate but doesn’t fully mitigate
    11. The best thing we could do is no delay and strip the IP but even then there are joins that can be done
    12. Something we are exploring
4. Brian
    13. Have you considered dividing things up, between multiple proxies and then can be joined in the agg service?
5. Charlie
    14. Haven’t really considered this yet
    15. Even with 1 proxy you can break it apart and shuffle reports
    16. Concern is how much added overhead does all of the fake reports add
    17. Efficiency vs privacy trade off
6. Brian
    18. Potentially also sustainability concerns, if we disguise traffic just to disguise traffic
7. Charlie
    19. We’ve discussed adding unconditional fake reports for all registrations even if there isn’t a conversion
    20. Might be ok for some ad techs but might not be feasible for all
    21. Trying to find the balance between most efficient and private
    22. We are investigating this further
    23. Related to delays, which provide extra protection for cross site data
8. Brian
    24. Interested in impact we are seeing on delays
9. Charlie
    25. No data to share right now, but delays can be amplified but users turning off the device or is off network. This goes up with more delay
    26. We are investigating this relationship further
10. Brian
    27. Are effective delays longer than expected delays?
11. Charlie
    28. Yes, something similar to that. There is some drop off
    29. We are looking into this data to see where we should set delays
12. Renan
    30. One other ad tech has posted on what they are seeing github issue #717
13. Charlie
    31. We have information in the debug reports that help to calculate this on your end as well
    32. You can look at the delta between debug reports and real reports
14. Alois
    33. Regarding source_registration_time, we planned to use it to support different aggregation groups
15. Charlie
    34. Will try to outline all of the considerations on the github issue
    35. We could expose the knobs we plan to adjust to the ad techs although this may cause a separate leak
16. Alois
    36. Having a fixed number of settings may be useful
17. Charlie
    37. There may be 1 set of settings that could be useful for everyone
    38. Still thinking through the best way to present all this

Github Issue 724 [https://github.com/WICG/attribution-reporting-api/issues/724](https://github.com/WICG/attribution-reporting-api/issues/724) 



1. Renan
    1. In some cases agg reports may arrive very late
    2. Each report gets a shared ID to see if it was processed already
    3. Reports that arrived on time and within 24 hours would have the same ID
    4. Potential new field to show what the delay is and you could batch by that
    5. Example: report on time, report a little delay, report with a lot of delay
    6. You could batch based on this new field “extra report delay”
    7. You would still get noise for the late arriving reports/batches
    8. We are looking for feedback on if this would be useful? And feedback on how ad techs are batching so we can set the values for this field?
2. Brian
    9. Ad techs don’t want to wait
3. Renan
    10. But how long are you waiting?
4. Alois
    11. Utility of this proposal is good. You don’t have to make a choice on delayed reports
    12. Regarding added noise, not fully sure yet
5. Renan
    13. Clarifying added noise. You wait 4 hours and process reports. Reports that come delayed after you can’t process these. With this proposal you would be able to
6. Charlie
    14. This proposal would reduce the delay for processing reports, but you would have fewer reports in the batch potentially
    15. You might not use the privacy budget in the most efficient way
    16. We are thinking of other proposals to improve this as well
7. Alois
    17. This proposal seems to be to reduce your latency
    18. Not sure it will influence our batching strategy
    19. At least we know data isn’t lost which is a huge win
8. Sid
    20. Assume you see reports from a region are always delayed
    21. Could you potentially say at the 2nd hour mark, that you don’t process reports for a specific region but rather do them later?
    22. 2 hour mark has normal reports, 24 hour mark as all the reports but some could have been processed earlier?
9. Charlie
    23. Need some way to encode these reports in a special batch
    24. The advertiser might be correlated with the specific region
    25. Harder to vary batching strategy based on a key in the encrypted payload
    26. But on shared ID it might be ok
    27. Advertiser in the clear already no need to encode it
    28. Might be common already: different size advertisers might need different batching sizes
10. Sid
    29. Trying to think about reducing the additional noising
    30. Are there ways to do additional dimensions outside of the cleartext
11. Charlie
    31. Right now i don’t think so
    32. We might need to think about this
12. Brian
    33. Is possible to provide some bits for different delay windows?
    34. If reports are typically delay we sent a longer batch time
13. Charlie
    35. Concern with embedding more information into the aggregatable report
    36. Want to make sure the existing strategies aren’t sufficient before adding additional info
14. Renan
    37. If folks could share their anticipated batching strategy that would be helpful
15. Alois
    38. We are willing to use hourly aggregate reports for both client reporting and campaign delivery 
    39. More flexibility would be great

GitHub Issue: [https://github.com/WICG/attribution-reporting-api/issues/725](https://github.com/WICG/attribution-reporting-api/issues/725)



* Akash
    * New reporting origin limit; limit on number of origins per site
    * This is mitigation for potential attacks of using multiple reporting origins to generate multiple reports and circumvent privacy limits
* Charlie
    * One site (adtech.com) that uses multiple origins (a.adtech.com, b.adtech.com, etc) measure the same event on a given publisher
    * One origin per site stays the same through the lifetime
    * Note to Google: We need to explain the migration strategy. Maybe limit to “1 current” that can be swapped out
    * Do you have a use-case for multiple origins for the same publisher?
* Sid
    * How does this apply to multiple sites for the same company (e.g. Google Ads Services vs. Double Click)
* Charlie: 
    * We are thinking through this use-case 
