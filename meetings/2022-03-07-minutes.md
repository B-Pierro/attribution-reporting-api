# Attribution Reporting API

March 7, 2022 @ 8-9am PT

This doc: bit.ly/ara-meeting-notes

Meet link: https://meet.google.com/jnn-rhxv-nsy
Previous meetings: https://github.com/WICG/conversion-measurement-api/tree/main/meetings
Meeting issue: https://github.com/WICG/conversion-measurement-api/issues/80

* Use Google meet “Raise hand” for queuing.
* If you can’t edit the doc during the meeting, try refreshing as permissions may have been updated after you loaded the page.
* If you are not admitted to the meeting, try rejoining. Google Meet has some UI that makes it easy to misclick if someone simultaneously requests to join while someone else is typing into the meeting chat.
* Please make sure to join W3C and WICG if you plan on participating

# Agenda
Add agenda topics here!

* Chair: John Delaney
* Scribe volunteer: Manny Isu
* palenica: Presentation on AGGREGATION_SERVICE_TEE
* https://github.com/WICG/conversion-measurement-api/issues/347


# Attendees — please sign yourself in! 

1. Martin Pal (Google Chrome)
2. Brian May (dstillery)
3. Matt Lamont (AdTheorent)
4. John Delaney (Google Chrome)
5. Michael Kleber (Google Chrome)
6. Jonasz Pamuła (RTB House)
7. Stacy Karthas (AdTheorent)
8. Manny Isu (Google Chrome) 
9. Andrew Paseltiner (Google Chrome)
10. Russell Stringham (Adobe) 
11. Wendell Baker (Yahoo)
12. Aloïs Bissuel (Criteo)
13. Alexandru Daicu (eyeo)
14. Christina Ilvento (Google Chrome)
15. Andrew Pascoe (NextRoll)
16. Robert Kubis (Google Chrome)
17. Peiwen Hu (Google Chrome)
18. Nan Lin (Google Chrome)
19. Lorenzo Hernandez (NextRoll)
20. Przemyslaw Iwanczak (RTB House)
21. Alex Cone (IAB Tech Lab)
22. Erik Taubeneck (Meta)
23. Badih Ghazi (Google Research)
24. Mariana Raykova (Google)
25. Alex Turner (Google Chrome)


# Notes

## Aggregation Service TEE Explainer Presentation [Martin Pal]

* [Martin Pal] It helps to measure in a privacy preserving way.
  * Basically, it supports aggregation of attribution reporting data.
  * Aggregate a collection of encrypted reports, aggregate them and provide a readable summary report.
  * This will be done in the Trusted Executed Environment (TEE) offered by cloud providers - To run it, you will need one of these cloud providers.
  * “Coordinator” provides Trust - makes sure you are running on approved binary and hardware. Iot will do the verification before granting access to the keys. Google will provide the code.

* [Brian May]: Are these reports opaque or will there be metadata?
* [Martin] There will be a section with metadata to show advertiser and publisher sites with corresponding information and batching key. We will want you to batch reports by the keys.
  * The proposal is to process each report once and not multiple times but open to feedback on impact.
* [John D] The encrypted report will also have a debug mode if you have it enabled for full fidelity to fine grained information
* [Alois Bissuel] Is it necessary for it to be hosted in the cloud? Does the enclave already exist within the cloud infrastructure provided?
* [Martin] For initial implementation, we are planning on a public cloud. If ad techs can demonstrate capability, we will be open to discussions
  * For the second piece, yes, cloud providers have this capability already.
  * For ad techs, you will need to collect these reports - set up servers to receive them, instrument websites, setup aggregations service in public cloud (instructions stool a WIP), send batch to agg service 
* [Brian May] Have you taken collaboration into account?
* [Martin] We will have both event level and aggregate available so you can use them to cross-check.
* [Christina] It allows multiple reporting origins to register views or clicks and measure conversions in those. In terms of aligning, there are some metadata data that should help to getting this validation but in terms of a fraction of events, it will be great to understand that use case better
* Action Item: Brian will dig something up and send out to make sure Google understands that use case better.
* [Alex Cone] It's really just that the incentives in the ecosystem favor this complexity that Brian is mentioning.
* [Martin] Primary standard is differential privacy - we will add some randomness to the output. The noise will be added to each aggregate value. We will also ensure that the batches are disjoint and no duplicates
* [Jonasz Pamula] Disjoint batches mechanism - A side effect is that the entire system will not work in real time, correct?
* [Martin] Yes, it is intentional to enforce some privacy. It is by design in that there is a delay between the time the attribution happens on the client and the aggregate side
* [Jonasz] I have no specific use case in mind at the moment - there was discussion for it to be real time. If we have a lot of aggregatable reports, the delay could be smaller and if there are less, it would have to be longer.
* [Andrew Pascoe] Advertisers want to see that campaigns are flowing. In terms of attribution, delays can be acceptable if there are purchase attributions. With different attributions, conversions can wait. “Spend” is critical that we really cannot delay it.
* [Brian] Can you send them faster if you have hundreds of thousands of reports?
* [Martin] The current design requires hourly granularity. But it may be possible to shorten this but for now, it is hourly
* [John] Happy to follow up on this and have further discussion
* [Christina] It will be helpful to understand the differences in those use cases
* [Andrew] The changes in campaign launches - agree that waiting a little while isn’t necessarily a big concern. The overall issue is the integration in order to track things - integration on advertiser side, DSPs. To clarify, I'm not *super* concerned about a delay of an hour: I think advertisers can have this explained. Was just trying to provide some use cases for more real-timey stuff.
* [Martin] Privacy budget key - the hash for the reporting origin
* [Brian] There are lots of problems with delays - will the delays impact what will be processed and the processability of things?
* [Martin] You will need to make a decision to wait for more reports to come or run it now…
* [Jonasz] Regarding the predeclared list of buckets - is there a limit to the number of buckets we can predeclare?
* [Martin] There is no limit. On the client, there will be a debug functionality
* [Brian] Will there be a relationship between the AD tech, the reports they are receiving and the agg service?
* [Martin] Yes, that is correct. There is a privacy accounting that keeps track of ad techs and all instances so that ad techs cannot use each other's privacy budget.
* [Erik] Is this the same as the MPC aggregate API?
* [Martin] There is an experimental project where we proposed to use MPC for the same task. We tried to design it so it is compatible with MPC.
* [Brian] Will we be able to start with a non Trusted Environment?
* [Martin] Yes. There will be a debug cookie and then we will offer a standalone binary so you can run it on your local machine to get a sense of how the aggregation works. However, if you want to play subject to all the rules, you will need to run it in the TEE
* [John] The client side support is not completely opaque to MPC vs TEE. It is designed to be amenable - there is no out of the box support for anything.
* [Erik] Has the MPC vs TEE conversation happened in any other forums? 
* [Christina] From Chrome perspective, TEE does make sense from a simplicity and performance standpoint. This is worth a follow-up discussion.
* [Erik] One of the proposals in the PATCG is an interoperable solution across browsers - it seems there are browsers concerned about security.
* [Michael Kleber] There is likely to be lots of ongoing discussion about MPC and TEE but I do not think all browsers agreeing on one and only answer is necessary to ship an API to be used across the web platform. 
* [Brian] If something works on MPC, will TEE be able to pick that up and work with it?
* [Martin] In general, yes.
* [Alex Cone] For interoperability, we need to make sure that where there are proposals that are covering the same use case, we are putting those out for consideration at the same time. Can the Chrome team sort out where the differences are so we can start aligning - have a focused discussion on why we should go one path than the other? For example, infrastructure - it will be nice to know for sure that if Chrome goes this route of TEE, that it will enable the same or very similar utilities as other browsers that decide to go with MPC route.
* [Michael] There are two different paths - what is the API inside the browser? Separately, what sort of aggregation system does interact with the reports? There are multiple proposals on the table for the second question, and there is a goal of reaching a conclusion on shipping one single API.
