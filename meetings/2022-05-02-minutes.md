# Attribution Reporting API

**April 18th meeting canceled, add any agenda items below for the next meeting**

May 2nd, 2022 @ 8-9am PT

This doc: [bit.ly/ara-meeting-notes](bit.ly/ara-meeting-notes)

Meet link: [https://meet.google.com/jnn-rhxv-nsy](https://meet.google.com/jnn-rhxv-nsy)

Previous meetings: [https://github.com/WICG/conversion-measurement-api/tree/main/meetings](https://github.com/WICG/conversion-measurement-api/tree/main/meetings)

Meeting issue: [https://github.com/WICG/conversion-measurement-api/issues/80](https://github.com/WICG/conversion-measurement-api/issues/80)



* Use Google meet “Raise hand” for queuing.
* If you can’t edit the doc during the meeting, try refreshing as permissions may have been updated after you loaded the page.
* If you are not admitted to the meeting, try rejoining. Google Meet has some UI that makes it easy to misclick if someone simultaneously requests to join while someone else is typing into the meeting chat.
* Please make sure to join [W3C](https://www.w3.org/) and [WICG](https://www.w3.org/community/wicg/) if you plan on participating


# Agenda



* Chair: John Delaney
* Scribe volunteer: Manny / Charlie

Please suggest agenda topics here! (either in a comment or a suggestion on the doc)



* Don Marti / Charlie Harrison: Default permissions policy
    * [https://github.com/WICG/conversion-measurement-api/pull/390](https://github.com/WICG/conversion-measurement-api/pull/390)
    * Should the API be disabled by default via PermissionPolicy?
* [#378](https://github.com/WICG/conversion-measurement-api/issues/378): Consider making source-side attributionsrc pings easier to associate with existing pings
    * Good enough mitigation to avoid double-counting?
* Aggregate API and ML ([#329](https://github.com/WICG/conversion-measurement-api/issues/329) ?): learning ML models inside the TEE in the future
* Aggregation Service on AWS Nitro Enclave (TEE) and local testing tool for aggregatable reports launched: [https://github.com/google/trusted-execution-aggregation-service](https://github.com/google/trusted-execution-aggregation-service)
    * For AWS testing, you need an AWS account, be registered for [the Privacy Sandbox Relevance and Measurement origin trial (OT)](https://developer.chrome.com/origintrials/#/view_trial/771241436187197441) and fill out the [onboarding form](https://forms.gle/EHoecersGKhpcLPNA). 


# Attendees — please sign yourself in! 

(Please sign in at the start of the meeting)



1.  Andrew Paseltiner (Google Chrome)
2.  Brian May (dstillery)
3.  Don Marti (CafeMedia)
4.  Charlie Harrison (Google Chrome)
5.  Manny Isu (Google Chrome)
6.  Matt Lamont (AdTheorent)
7.  Michael Kleber (Google Chrome)
8.  Stacy Karthas (AdTheorent)
9.  Joel Pfeiffer (MSFT)
10.  Angelina Eng (IAB Tech Lab/IAB)
11.  Andrew Pascoe (NextRoll)
12.  Christina Ilvento(Google Chrome)
13. Martin Pal (Google Chrome)
14.  Alex Turner (Google Chrome)
15.  Aloïs Bissuel (Criteo)
16.  Sid Sahoo (Google Chrome)
17.  Nan Lin (Google Chrome)
18. John Delaney (Google Chrome)
19. Alexandre Gilotte (Criteo)
20. Alexandru Daicu (Eyeo)
21. Badih Ghazi (Google Research)
22. Robert Kubis (Google Chrome)
23. Aditya Desai (Amazon)
24. Alex Cone (IAB Tech Lab)
25.  
26.  
27. 


# Notes



* Don Marti / Charlie Harrison: Default permissions policy
    * [https://github.com/WICG/conversion-measurement-api/pull/390](https://github.com/WICG/conversion-measurement-api/pull/390)
    * Should the API be disabled by default via PermissionPolicy?
    * [Don] Are there sensitive contexts that would find it hard to turn it off with a permissions policy header or if there are more sites that want to participate in ARA who will find it difficult to turn it on with permissions policy header? 
        * We are concerned about small publishers and retailers that want ARA but do not have a lot of development skills. 
        * Also concerned about sites that follow general web development rules and have third party scripts that may call ARA on their site.
    * [Brian] The people who do not pay attention to their website once setup. I would advocate for making it up rather than default
    * [Charlie] To counter something Don mentioned, it is a really common use case for a simple blog to embed a copy/paste ad tag but the sites are completely unmaintained.
        * [Don] I agree that those categories of sites need to be addressed. From the point of view of the web host, having it as an opt-in will give them the opportunity to offer a value-added service and reach out.
        * [Charlie] We hope that we could move the API to a point where the vast majority of the work could be done by 3rd party on behalf of the publisher. It should have most permissions available to do this migration without the publisher helping.
        * [Michael] To point out, this is a discussion we had before we started the privacy sandbox incubation proposal. The takeaway is that the number of adtech is about a million and advertisers are about 10K and 100 buyers in the RTB space and like 10 on the sell side. For any of the PS APIs, try to focus designs on adoption being required by the smallest number of people to get back to somewhere reasonable. This has been the design principle of the PS - any API where the default requires a million websites is something that isn’t feasible in the short term.
        * [Don] How many less well maintained sensitive context sites have javascript on them? It seems like the people who are in the position to make money in advertising will be the ones who get paid to do 5 mins of work but folks who inherit the site but do not understand advertising will not be able to.
        * [Michael] This was shut down loudly when we initially discussed this point.
        * [Don] Google got a lot of bad reaction from FLoC being on by default
        * [Michael] The change in defaults, from FLoC to Topics API, is that the new feature only does something if the website asks it to.  That is very different from any kind of double-adoption approach, where API use would require both ad tech to use it *and* a million publishers explicitly giving them permission to do so.
    * [Brian] I think this is one of many changes coming over the next few years. We will need to have a common set of expectations for folks - we need to figure out how this works with everything else
        * [Charlie] Agree. Our expectation is that if you’re a publisher, you do not have to do any work. You can have migration happen on your behalf by 3rd parties.
    * [Erik] Will this only apply to websites who have 3rd party javascripts? So you’re only opting people into an API that is more secure than what they are using today?
        * [Charlie] That sounds right to me if I understand correctly.
    * [Brian] I think it will be helpful that whatever is decided is enumerated and communicated in the same way.
    * [Don] There is a cycle of opt-out headers that developers of web servers are having to keep track of… to Brian’s point, a lot of the issues will be better handled with open source
    * [Charlie] Maybe we should continue discussion on the issue. I encourage folks who haven’t spoken up to please do so - it will be good to hear opinions.
    * [Brian] +1 to keeping the issue open
    * [Charlie] We might need a new issue for this. Don, can you file an issue on our repo asking if this should be enabled by default?
        * [Don] Sounds good!
    * [Angelina] Most often, agencies and advertisers do not provide AR to publishers given the sensitivity that advertisers have about sharing that data. Also, each campaign's attribution can vary from business line to business line - DV360, last click attribution, etc. Need to understand when we are providing permissioning and how those scenarios might come into play
        * [Charlie] I do not think we have the permissions infra to support that level of granularity; for the first point.
        * The second point is how the architecture of the API is managed. For now, it is impossible to do that after the fact for the ARA because all attributions happen on device.
    * [Brian] Can we impose on the chrome team to compile a set of places where the default might be set? Also, the design principles used?
        * [John] I think this makes sense - maybe we can document it as part of this issue that gets filed. We can start with ARA and scale to other APIs
        * [Angelina] Also outline things that can be customizable like event priorities, mutual latency, controlling the models - campaign level or publisher level, etc.
        * [John] This sounds like a slightly different matrix. On this point, I will recommend filing an issue
* [#378](https://github.com/WICG/conversion-measurement-api/issues/378): Consider making source-side attributionsrc pings easier to associate with existing pings
    * Good enough mitigation to avoid double-counting?
    * [John] For context, the current explainer needs 2 pings to register an impression. This was done so we do not allow pre-existing image tags to register for impressions and conversions. There is some complexity:
        * Performance
        * Multiple report use case - possible double counting for ad techs. Overall not trivial to do by default
    * I recommend looking at the issue since this is very complicated
    * Solution #1: Adding a browser provided key
    * Solution #2: Make it optional and modifiable
    * How real of an issue is double counting? Need some feedback if folks have any thoughts
    * [Angelina] There's always been an issue for dedupe on the buyer side, but has some pros and cons - all ad tech companies currently get pings and it allows them to optimize towards it, and 2.) At the end, whatever the advertiser deems is who should get the credit. These two should be considered 2 separate use cases so it gives them the opportunity to keep optimizing.
    * [John] This is more of an issue for double counting clicks/views
    * [Angelina] There are IAB and MRC rules (and measurement guidelines) for double counting within a certain time frame.
        * **[https://www.iab.com/wp-content/uploads/2015/06/click-measurement-guidelines2009.pdf](https://www.iab.com/wp-content/uploads/2015/06/click-measurement-guidelines2009.pdf)**
        * **[http://www.mediaratingcouncil.org/MRC%20Standards%20Listing%2003-10-20.pdf](http://www.mediaratingcouncil.org/MRC%20Standards%20Listing%2003-10-20.pdf)**
    * [Brian] Having a single url vs multiple urls, where somebody can debug will save everybody a ton of pain.
    * [Charlie] On the simplicity, it doesn’t cut across every dimension. Two urls could also be looked at as a simpler solution depending on how you look at it.

        Also to clarify on Angelina’s point - this will not be a solution where the browser can help prevent duplication. The issue is that we have a new API surface that if misused, could perpetuate duplication issues. We need to understand how big a concern it is.

* Aggregate API and ML ([#329](https://github.com/WICG/conversion-measurement-api/issues/329) ?): learning ML models inside the TEE in the future
    * [Alois Bissuel]: This API is really useful for reporting, but that’s only one part of the ad-techs job. We need to learn how to bid / learn which ads most successful
    * Using the API for learning models is quite difficult. We have been able to somehow bend it using aggregated data. Complicated though! Public contest
    * Ask / Feedback: would it be useful to have some form of model learning directly inside the servers / TEE.
    * For Criteo it would make the measurement API much more worthwhile
    * [Alex Cone]: Makes a ton of sense. Would definitely be interested in seeing us explore it.
    * [John D] Martin not in the emeting, but hopefully can have more discussion offline
    * [Brian May] want to get attribution reporting right. New things should go in a separate API
    * [John D] Comes down to how much overlap.
    * [Brian] Shouldn’t get harder to do reporting if we add the other layer.
    * [Alexandre Gilotte] Working on model predicting w/ aggregated data. It is very complicated and I hope to not use it in production. We have all the features and training set in the TEE. It would be so much cleaner to do this in the TEE. Much simpler for us and the whole ecosystem.
    * [John] can we document this on the original issue? We can prioritize based on how useful we think it would be.
* Aggregation Service on AWS Nitro Enclave (TEE) and local testing tool for aggregatable reports launched: [https://github.com/google/trusted-execution-aggregation-service](https://github.com/google/trusted-execution-aggregation-service)
    * For AWS testing, you need an AWS account, be registered for [the Privacy Sandbox Relevance and Measurement origin trial (OT)](https://developer.chrome.com/origintrials/#/view_trial/771241436187197441) and fill out the [onboarding form](https://forms.gle/EHoecersGKhpcLPNA). 
    * [Robert Kubis] Launched the aggregation service. If you want to experiment with aggregatable reports
    * If you want to do AWS testing, need an AWS account and sign up for the OT, as well as a cloud onboarding form
    * Please file issues on the github repo or an email
    * [John] Lots of documentation there as well, recommend folks read through it.
    * [Robert] we are planning a live demo. Not scheduled yet though
